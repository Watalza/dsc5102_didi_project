{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import udf, from_unixtime\n",
    "from pyspark.sql import functions as F\n",
    "from math import radians, cos, sin, asin, sqrt, atan2, degrees\n",
    "from datetime import datetime\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"Simple App\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").\\\n",
    "    appName(\"Simple App\").\\\n",
    "    config(\"spark.some.config.option\", \"some-value\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure directories for source data files and log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_1_path = 'xian_sample_1.csv'\n",
    "full_data_1_path = 'gps_20161001.csv'\n",
    "sample_dir = '../data/'\n",
    "full_data_dir = '../full_data/'\n",
    "output_dir = '../output/'\n",
    "boundary_dir = '../log/boundary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = sample_dir + sample_data_1_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "SHOWLINES = 5\n",
    "TIMEFORMAT = \"yyyy-MM-dd HH:mm:ss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(df):\n",
    "    if DEBUG:\n",
    "        print(df.show(SHOWLINES))\n",
    "        df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(longit_a, latit_a, longit_b, latit_b):\n",
    "    \"\"\"\n",
    "    Reference:\n",
    "        https://medium.com/@nikolasbielski/using-a-custom-udf-in-pyspark-to-compute-haversine-distances-d877b77b4b18\n",
    "    Return:\n",
    "        double(,3): unit in km\n",
    "    \"\"\" \n",
    "    # Transform to radians\n",
    "    longit_a, latit_a, longit_b, latit_b = map(radians, [longit_a,  latit_a, longit_b, latit_b])\n",
    "    dist_longit = longit_b - longit_a\n",
    "    dist_latit = latit_b - latit_a\n",
    "    # Calculate area\n",
    "    area = sin(dist_latit/2)**2 + cos(latit_a) * sin(dist_longit/2)**2\n",
    "    # Calculate the central angle\n",
    "    central_angle = 2 * asin(sqrt(area))\n",
    "    radius = 6371\n",
    "    # Calculate Distance, unit = km\n",
    "    distance = central_angle * radius\n",
    "    return abs(round(distance, 3))\n",
    "\n",
    "udf_get_distance = F.udf(get_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocity(distance, time):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        double(,3): unit in km/h\n",
    "    \"\"\" \n",
    "    return(round(distance/time*3600, 3))\n",
    "\n",
    "udf_get_velocity = F.udf(get_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(longit_a, latit_a, longit_b, latit_b):\n",
    "    diffLong = longit_b - longit_a\n",
    "        \n",
    "    x = sin(diffLong) * cos(latit_b)\n",
    "    y = cos(latit_a) * sin(latit_b) - (sin(latit_a)\n",
    "            * cos(latit_b) * cos(diffLong))\n",
    "\n",
    "    initial_bearing = atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "    return round(compass_bearing, 3)\n",
    "\n",
    "udf_get_direction = F.udf(get_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data from csv using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Didi data with pre-defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [StructField('driver_id', StringType(), True), \n",
    "          StructField('order_id', StringType(), True),\n",
    "         StructField('timestamp', StringType(), True),\n",
    "         StructField('lon', DoubleType(), True),\n",
    "         StructField('lat', DoubleType(), True)]\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_df = sqlContext.read.csv(data_file, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+---------+--------+\n",
      "|           driver_id|            order_id| timestamp|      lon|     lat|\n",
      "+--------------------+--------------------+----------+---------+--------+\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|1475277482|108.92466|34.27657|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|1475277488|108.92527|34.27658|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|1475277506| 108.9276|34.27659|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|1475277476|108.92399|34.27655|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|1475277515| 108.9291| 34.2766|\n",
      "+--------------------+--------------------+----------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(didi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert unixtime to proper timestamp format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_df_1 = didi_df.withColumn('timestamp', F.from_unixtime(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+\n",
      "|           driver_id|            order_id|          timestamp|      lon|     lat|\n",
      "+--------------------+--------------------+-------------------+---------+--------+\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|2016-10-01 07:18:02|108.92466|34.27657|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|2016-10-01 07:18:08|108.92527|34.27658|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|2016-10-01 07:18:26| 108.9276|34.27659|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|2016-10-01 07:17:56|108.92399|34.27655|\n",
      "|a01b8439e1e42ffcd...|f11440a64a0f084fe...|2016-10-01 07:18:35| 108.9291| 34.2766|\n",
      "+--------------------+--------------------+-------------------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(didi_df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create index for each order_id, sorted by timestamp in descending order. <br/>\n",
    "This is to identify nodes at time t and t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(didi_df_1['order_id']).orderBy(didi_df_1['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+----+\n",
      "|           driver_id|            order_id|          timestamp|      lon|     lat|rank|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+\n",
      "|a01b8439e1e42ffcd...|210acc529e4b9fc55...|2016-10-01 21:45:29|108.94276|34.27099|   1|\n",
      "|a01b8439e1e42ffcd...|210acc529e4b9fc55...|2016-10-01 21:45:32|108.94276|34.27099|   2|\n",
      "|a01b8439e1e42ffcd...|210acc529e4b9fc55...|2016-10-01 21:45:35|108.94262|34.27108|   3|\n",
      "|a01b8439e1e42ffcd...|210acc529e4b9fc55...|2016-10-01 21:45:38|108.94242|34.27108|   4|\n",
      "|a01b8439e1e42ffcd...|210acc529e4b9fc55...|2016-10-01 21:45:41|108.94225|34.27108|   5|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_df_2 = didi_df_1.withColumn('rank', F.dense_rank().over(window))\n",
    "check_df(didi_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a duplicate for t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_df_2_post = didi_df_2.\\\n",
    "    withColumnRenamed(\"rank\", \"rank_new\").\\\n",
    "    withColumnRenamed(\"timestamp\", \"timestamp_new\").\\\n",
    "    withColumnRenamed(\"lon\", \"lon_new\").\\\n",
    "    withColumnRenamed(\"lat\", \"lat_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_df_2_post = didi_df_2_post.drop('driver_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+--------+--------+\n",
      "|            order_id|      timestamp_new|  lon_new| lat_new|rank_new|\n",
      "+--------------------+-------------------+---------+--------+--------+\n",
      "|210acc529e4b9fc55...|2016-10-01 21:45:29|108.94276|34.27099|       1|\n",
      "|210acc529e4b9fc55...|2016-10-01 21:45:32|108.94276|34.27099|       2|\n",
      "|210acc529e4b9fc55...|2016-10-01 21:45:35|108.94262|34.27108|       3|\n",
      "|210acc529e4b9fc55...|2016-10-01 21:45:38|108.94242|34.27108|       4|\n",
      "|210acc529e4b9fc55...|2016-10-01 21:45:41|108.94225|34.27108|       5|\n",
      "+--------------------+-------------------+---------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- timestamp_new: string (nullable = true)\n",
      " |-- lon_new: double (nullable = true)\n",
      " |-- lat_new: double (nullable = true)\n",
      " |-- rank_new: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(didi_df_2_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the two tables for t and t+1 on order ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+\n",
      "|            order_id|           driver_id|          timestamp|      lon|     lat|rank|      timestamp_new|  lon_new| lat_new|rank_new|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:29|108.94276|34.27099|   1|2016-10-01 21:45:32|108.94276|34.27099|       2|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:32|108.94276|34.27099|   2|2016-10-01 21:45:35|108.94262|34.27108|       3|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:35|108.94262|34.27108|   3|2016-10-01 21:45:38|108.94242|34.27108|       4|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:38|108.94242|34.27108|   4|2016-10-01 21:45:41|108.94225|34.27108|       5|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:41|108.94225|34.27108|   5|2016-10-01 21:45:44|108.94204|34.27108|       6|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- timestamp_new: string (nullable = true)\n",
      " |-- lon_new: double (nullable = true)\n",
      " |-- lat_new: double (nullable = true)\n",
      " |-- rank_new: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_df_3 = didi_df_2.alias('a').join(didi_df_2_post.alias('b'),on = 'order_id').where('a.rank == b.rank_new-1')\n",
    "check_df(didi_df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get distance using coordinates of $node_t$ and $node_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "didi_df_4 = didi_df_3.withColumn('distance', udf_get_distance(\n",
    "    didi_df_3.lon, didi_df_3.lat, \n",
    "    didi_df_3.lon_new, didi_df_3.lat_new).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+\n",
      "|            order_id|           driver_id|          timestamp|      lon|     lat|rank|      timestamp_new|  lon_new| lat_new|rank_new|distance|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:29|108.94276|34.27099|   1|2016-10-01 21:45:32|108.94276|34.27099|       2|     0.0|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:32|108.94276|34.27099|   2|2016-10-01 21:45:35|108.94262|34.27108|       3|   0.017|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:35|108.94262|34.27108|   3|2016-10-01 21:45:38|108.94242|34.27108|       4|    0.02|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:38|108.94242|34.27108|   4|2016-10-01 21:45:41|108.94225|34.27108|       5|   0.017|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:41|108.94225|34.27108|   5|2016-10-01 21:45:44|108.94204|34.27108|       6|   0.021|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- timestamp_new: string (nullable = true)\n",
      " |-- lon_new: double (nullable = true)\n",
      " |-- lat_new: double (nullable = true)\n",
      " |-- rank_new: integer (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(didi_df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get time difference between $node_t$ and $node_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeDiff = (F.unix_timestamp('timestamp_new', format=TIMEFORMAT)\n",
    "            - F.unix_timestamp('timestamp', format=TIMEFORMAT))\n",
    "didi_df_5 = didi_df_4.withColumn(\"eclipse_time\", timeDiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get velocity between $node_t$ and $node_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_df_6 = didi_df_5.withColumn(\"velocity\", udf_get_velocity(\n",
    "    didi_df_5.distance, didi_df_5.eclipse_time).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+------------+--------+\n",
      "|            order_id|           driver_id|          timestamp|      lon|     lat|rank|      timestamp_new|  lon_new| lat_new|rank_new|distance|eclipse_time|velocity|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+------------+--------+\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:29|108.94276|34.27099|   1|2016-10-01 21:45:32|108.94276|34.27099|       2|     0.0|           3|     0.0|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:32|108.94276|34.27099|   2|2016-10-01 21:45:35|108.94262|34.27108|       3|   0.017|           3|    20.4|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:35|108.94262|34.27108|   3|2016-10-01 21:45:38|108.94242|34.27108|       4|    0.02|           3|    24.0|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:38|108.94242|34.27108|   4|2016-10-01 21:45:41|108.94225|34.27108|       5|   0.017|           3|    20.4|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:41|108.94225|34.27108|   5|2016-10-01 21:45:44|108.94204|34.27108|       6|   0.021|           3|    25.2|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- timestamp_new: string (nullable = true)\n",
      " |-- lon_new: double (nullable = true)\n",
      " |-- lat_new: double (nullable = true)\n",
      " |-- rank_new: integer (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- eclipse_time: long (nullable = true)\n",
      " |-- velocity: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(didi_df_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get compass bearing when travelling from $node_t$ to $node_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_df_7 = didi_df_6.withColumn('direction', udf_get_direction(\n",
    "    didi_df_6.lon, didi_df_6.lat, \n",
    "    didi_df_6.lon_new, didi_df_6.lat_new).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+------------+--------+---------+\n",
      "|            order_id|           driver_id|          timestamp|      lon|     lat|rank|      timestamp_new|  lon_new| lat_new|rank_new|distance|eclipse_time|velocity|direction|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+------------+--------+---------+\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:29|108.94276|34.27099|   1|2016-10-01 21:45:32|108.94276|34.27099|       2|     0.0|           3|     0.0|      0.0|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:32|108.94276|34.27099|   2|2016-10-01 21:45:35|108.94262|34.27108|       3|   0.017|           3|    20.4|   56.172|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:35|108.94262|34.27108|   3|2016-10-01 21:45:38|108.94242|34.27108|       4|    0.02|           3|    24.0|   90.002|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:38|108.94242|34.27108|   4|2016-10-01 21:45:41|108.94225|34.27108|       5|   0.017|           3|    20.4|   90.001|\n",
      "|210acc529e4b9fc55...|a01b8439e1e42ffcd...|2016-10-01 21:45:41|108.94225|34.27108|   5|2016-10-01 21:45:44|108.94204|34.27108|       6|   0.021|           3|    25.2|   90.002|\n",
      "+--------------------+--------------------+-------------------+---------+--------+----+-------------------+---------+--------+--------+--------+------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- driver_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- timestamp_new: string (nullable = true)\n",
      " |-- lon_new: double (nullable = true)\n",
      " |-- lat_new: double (nullable = true)\n",
      " |-- rank_new: integer (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- eclipse_time: long (nullable = true)\n",
      " |-- velocity: double (nullable = true)\n",
      " |-- direction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(didi_df_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construct the Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the boundaries from existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>time_max</th>\n",
       "      <th>time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../data/xian_sample_1.csv</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>00:13:26</td>\n",
       "      <td>34.27678</td>\n",
       "      <td>34.21653</td>\n",
       "      <td>108.98842</td>\n",
       "      <td>108.92246</td>\n",
       "      <td>2016-10-01 23:13:11</td>\n",
       "      <td>2016-10-01 07:17:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/xian_sample_2.csv</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>00:13:27</td>\n",
       "      <td>34.23308</td>\n",
       "      <td>34.21647</td>\n",
       "      <td>108.93969</td>\n",
       "      <td>108.91170</td>\n",
       "      <td>2016-10-02 05:52:25</td>\n",
       "      <td>2016-10-02 05:47:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data_full/xian/gps_20161002</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>00:19:22</td>\n",
       "      <td>34.28017</td>\n",
       "      <td>34.20531</td>\n",
       "      <td>108.99860</td>\n",
       "      <td>108.91119</td>\n",
       "      <td>2016-10-03 00:01:11</td>\n",
       "      <td>2016-10-02 00:01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data_full/xian/gps_20161001</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>00:22:49</td>\n",
       "      <td>34.28022</td>\n",
       "      <td>34.20531</td>\n",
       "      <td>108.99860</td>\n",
       "      <td>108.91118</td>\n",
       "      <td>2016-10-02 00:01:10</td>\n",
       "      <td>2016-10-01 00:02:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename execution_time   lat_max   lat_min  \\\n",
       "../data/xian_sample_1.csv       03/08/2019       00:13:26  34.27678  34.21653   \n",
       "../data/xian_sample_2.csv       03/08/2019       00:13:27  34.23308  34.21647   \n",
       "../data_full/xian/gps_20161002  03/08/2019       00:19:22  34.28017  34.20531   \n",
       "../data_full/xian/gps_20161001  03/08/2019       00:22:49  34.28022  34.20531   \n",
       "\n",
       "                                  lon_max    lon_min             time_max  \\\n",
       "../data/xian_sample_1.csv       108.98842  108.92246  2016-10-01 23:13:11   \n",
       "../data/xian_sample_2.csv       108.93969  108.91170  2016-10-02 05:52:25   \n",
       "../data_full/xian/gps_20161002  108.99860  108.91119  2016-10-03 00:01:11   \n",
       "../data_full/xian/gps_20161001  108.99860  108.91118  2016-10-02 00:01:10   \n",
       "\n",
       "                                           time_min  \n",
       "../data/xian_sample_1.csv       2016-10-01 07:17:26  \n",
       "../data/xian_sample_2.csv       2016-10-02 05:47:09  \n",
       "../data_full/xian/gps_20161002  2016-10-02 00:01:01  \n",
       "../data_full/xian/gps_20161001  2016-10-01 00:02:12  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_df = pd.read_csv(boundary_dir, skipinitialspace=True )\n",
    "boundary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_max = boundary_df[\"lat_max\"].max()\n",
    "lat_min = boundary_df[\"lat_min\"].min()\n",
    "lon_max = boundary_df[\"lon_max\"].max()\n",
    "lon_min = boundary_df[\"lon_min\"].min()\n",
    "time_max = boundary_df[\"time_max\"].max()\n",
    "time_min = boundary_df[\"time_min\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.28022 34.20531 108.9986 108.91118 2016-10-03 00:01:11 2016-10-01 00:02:12\n"
     ]
    }
   ],
   "source": [
    "print(lat_max, lat_min, lon_max, lon_min, time_max, time_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
